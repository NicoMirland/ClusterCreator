- name: Move kubeconfig to user home
  hosts: all
  vars:
    cluster_config: "{{ lookup('file', 'tmp/{{ cluster_name }}/cluster_config.json') | from_json }}"
  tags:
    - move_kubeconfig_remote
  tasks:
    - name: Ensure .kube exists in ssh users' account
      ansible.builtin.file:
        path: "{{ cluster_config.ssh.ssh_home }}/.kube"
        state: directory
        mode: '0700'
        owner: "{{ cluster_config.ssh.ssh_user }}"
        group: "{{ cluster_config.ssh.ssh_user }}"
      become: false
      when: inventory_hostname not in groups['kube_etcd_servers']
    - name: Configure .kube/config files in user home
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "{{ cluster_config.ssh.ssh_home }}/.kube/config"
        remote_src: yes
        owner: "{{ cluster_config.ssh.ssh_user }}"
        group: "{{ cluster_config.ssh.ssh_user }}"
        mode: '0700'
      become: true
      when: inventory_hostname in groups['kube_api_servers']
    - name: restart kubelet for config changes
      service:
        name: kubelet
        state: restarted
      become: true
      when: inventory_hostname not in groups['kube_etcd_servers']

- name: Ensure ~/.kube/exists locally
  hosts: localhost
  tags:
    - move_kubeconfig_local
  tasks:
    - name: Ensure .kube exists in ssh users' account
      ansible.builtin.file:
        path: "{{ lookup('env', 'HOME') }}/.kube/"
        state: directory
        mode: '0700'
- name: Fetch Kubernetes config file to local machine
  hosts: kube_api_servers[0]
  gather_facts: false
  vars:
    cluster_config: "{{ lookup('file', 'tmp/{{ cluster_name }}/cluster_config.json') | from_json }}"
  tags:
    - move_kubeconfig_local
  tasks:
    - name: Fetch Kube config from the first control plane server
      ansible.builtin.fetch:
        src: "{{ cluster_config.ssh.ssh_home }}/.kube/config"
        dest: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
        flat: yes
      become: false  # Ensure this is correctly set based on your needs
      run_once: true

- name: Run local kubectl commands and configure kubeconfig
  hosts: localhost
  connection: local
  gather_facts: false
  vars:
    cluster_config: "{{ lookup('file', 'tmp/{{ cluster_name }}/cluster_config.json') | from_json }}"
  tags:
    - rename_kubeconfig_context
  tasks:
    - name: Check if the kubectl context needs renaming
      ansible.builtin.shell:
        cmd: kubectl config get-contexts -o name
      environment:
        KUBECONFIG: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
      register: kubectl_contexts
      changed_when: false
      ignore_errors: yes
    - name: Rename kubectl context
      ansible.builtin.command:
        cmd: kubectl config rename-context kubernetes-admin@{{ cluster_config.cluster_name }} {{ cluster_config.cluster_name }}
      environment:
        KUBECONFIG: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
      when:
        - "'kubernetes-admin@' + cluster_config.cluster_name in kubectl_contexts.stdout"
        - cluster_config.cluster_name + ' not in kubectl_contexts.stdout'
    - name: Replace kubernetes-admin username in kubeconfig
      ansible.builtin.replace:
        path: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
        regexp: "kubernetes-admin"
        replace: "{{ cluster_config.cluster_name }}-admin"
    - name: Replace API server address in kubeconfig
      ansible.builtin.replace:
        path: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
        regexp: "{{ cluster_config.kube_vip.vip_hostname }}"
        replace: "{{ cluster_config.kube_vip.vip }}"
    - name: Set the current context to the new cluster name
      ansible.builtin.command:
        cmd: kubectl config use-context {{ cluster_config.cluster_name }}
      environment:
        KUBECONFIG: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
    - name: Get nodes to verify configuration
      ansible.builtin.command:
        cmd: kubectl get nodes
      environment:
        KUBECONFIG: "{{ lookup('env', 'HOME') }}/.kube/{{ cluster_config.kubeconfig_file_name }}"
      register: kubectl_output
    - name: Show kubectl get nodes output
      ansible.builtin.debug:
        var: kubectl_output.stdout_lines

- name: Untaint control plane if no worker nodes will be added
  hosts: kube_api_servers[0]
  gather_facts: false
  vars:
    cluster_config: "{{ lookup('file', 'tmp/{{ cluster_name }}/cluster_config.json') | from_json }}"
  tags:
    - untaint_control_plane
  tasks:
    - name: Calculate quantity of non-API/ETCD nodes
      set_fact:
        non_api_etcd_node_count: "{{ groups['all'] | difference(groups['kube_api_servers'] | default([])) | difference(groups['kube_etcd_servers'] | default([])) | length }}"
    - name: Check for master NoSchedule taints on nodes
      ansible.builtin.command: kubectl get nodes -o json
      register: nodes_json
      when: non_api_etcd_node_count == "0"
    - name: Set fact for nodes with master NoSchedule taint
      set_fact:
        master_taint_nodes: "{{ nodes_json.stdout | from_json | json_query(query) }}"
      vars:
        query: "items[?spec.taints[?key=='node-role.kubernetes.io/master' && effect=='NoSchedule']].metadata.name"
      when: non_api_etcd_node_count == "0"
    - name: Untaint nodes with master NoSchedule taint
      ansible.builtin.command: kubectl taint nodes {{ item }} node-role.kubernetes.io/master:NoSchedule-
      loop: "{{ master_taint_nodes }}"
      when:
        - non_api_etcd_node_count == "0"
        - master_taint_nodes | default([]) | length > 0
      ignore_errors: yes
    - name: Set fact for nodes with control-plane NoSchedule taint
      set_fact:
        control_plane_taint_nodes: "{{ nodes_json.stdout | from_json | json_query(query) }}"
      vars:
        query: "items[?spec.taints[?key=='node-role.kubernetes.io/control-plane' && effect=='NoSchedule']].metadata.name"
      when: non_api_etcd_node_count == "0"
    - name: Untaint nodes with control-plane NoSchedule taint
      ansible.builtin.command: kubectl taint nodes {{ item }} node-role.kubernetes.io/control-plane:NoSchedule-
      loop: "{{ control_plane_taint_nodes }}"
      when:
        - non_api_etcd_node_count == "0"
        - control_plane_taint_nodes | default([]) | length > 0
      ignore_errors: yes
